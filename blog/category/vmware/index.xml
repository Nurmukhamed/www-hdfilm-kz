<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>vmware on Нұрмұхамед Артықалы</title><link>https://www.hdfilm.kz/blog/category/vmware/</link><description>Recent content in vmware on Нұрмұхамед Артықалы</description><generator>Hugo -- gohugo.io</generator><language>ru-RU</language><lastBuildDate>Thu, 28 May 2020 12:30:30 +0600</lastBuildDate><atom:link href="https://www.hdfilm.kz/blog/category/vmware/index.xml" rel="self" type="application/rss+xml"/><item><title>Инструкция по настройке Kubernetes Bare-metall в среде виртуализации Vmware EsxI 6.5</title><link>https://www.hdfilm.kz/blog/2020/05/28/2018-kubernetes-manual/</link><pubDate>Thu, 28 May 2020 12:30:30 +0600</pubDate><guid>https://www.hdfilm.kz/blog/2020/05/28/2018-kubernetes-manual/</guid><description>&lt;p>&lt;strong>Инструкция по настройке Kubernetes Bare-metall в среде виртуализации Vmware EsxI 6.5&lt;/strong>&lt;/p></description></item><item><title>как заменить образ сетевой карты в виртуальной машине на образ ipxe</title><link>https://www.hdfilm.kz/blog/2015/07/24/vmwareaddipxemromtovmsnicbios/</link><pubDate>Fri, 24 Jul 2015 00:00:00 +0000</pubDate><guid>https://www.hdfilm.kz/blog/2015/07/24/vmwareaddipxemromtovmsnicbios/</guid><description>Небольшая статья - как заменить образ сетевой карты в виртуальной машине на образ ipxe.
На сайте ipxe нашел как можно заменить образы сетевой карты на свои. Но это все делается ручками. Что делать, если у тебя виртуальных машин больше 100 и более.
Нужно автоматизировать данный процесс. Используем powershell и powercli. Также нам понадобятся putty, pscp.
Использовал информацию со следующих сайтов:
Using plink to modify ESXi host configuration files via SSH from a PowerCLI script Using iPXE in VMware Changing VMX files just got a whole lot easier.</description></item><item><title>CoreOS: Установка кластера CoreOS</title><link>https://www.hdfilm.kz/coreos-setup-coreos-cluster/</link><pubDate>Wed, 25 Feb 2015 00:00:00 +0000</pubDate><guid>https://www.hdfilm.kz/coreos-setup-coreos-cluster/</guid><description>Установка кластера CoreOS
Рекомендую ознакомится со следующей статьей, здесь достаточно подробно описана технология coreos.
Для меня самой большой проблемой было понять, для чего нужен https://discovery.etcd.io/ и как быть, если в корпоративной сети нет доступа к этому ресурсу. Пока не прочел данную статью, где описан вариант Easy Development/Testing Cluster. этот вариант установки кластера буду использовать.
Варианты установки:
Установка через Cd-rom Установка через netboot Установка через Cd-rom
Я использовал этот вариант как самый простой способ.</description></item><item><title>CoreOS: Запуск служб, тестирование работы</title><link>https://www.hdfilm.kz/coreos-start-services-testing/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.hdfilm.kz/coreos-start-services-testing/</guid><description/></item><item><title>CoreOS: Настройка сервисов в кластере CoreOS</title><link>https://www.hdfilm.kz/coreos-setting-services-in-coreos/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.hdfilm.kz/coreos-setting-services-in-coreos/</guid><description>Введение
Рекомендую ознакомиться со следующей инструкцией. Очень подробное описание как работать с CoreOS.
Подключение к кластеру
Подключаемся к любому узлу кластера, я создал пользователя nurmukhamed.
slogin nurmukhamed@a.coreos.nurm.local Создание конфигурационных файлов
Создайте следующие файлы
a.httpd
cat &amp;lt;&amp;lt;EOF &amp;gt; a-httpd.service [Unit] Description=A.HTTPD service After=etcd.service After=docker.service [Service] TimeoutStartSec=0 KillMode=none ExecStartPre=-/usr/bin/docker kill a-httpd ExecStartPre=-/usr/bin/docker rm a-httpd ExecStartPre=/usr/bin/docker pull hub.nurm.local:5000/centos-test-httpd ExecStartPre=/usr/bin/ip a add 192.168.254.207/25 dev vlan501 ExecStart=/usr/bin/docker run --name a-httpd -p 192.168.254.207:80:80 hub.nurm.local:5000/centos-test-httpd /usr/sbin/apachectl -D FOREGROUND ExecStop=/usr/bin/docker kill a-httpd ExecStop=/usr/bin/ip ad del 192.</description></item><item><title>CoreOS: Описание железа, виртуальных машин, топология сети</title><link>https://www.hdfilm.kz/coreos-hardware-description/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.hdfilm.kz/coreos-hardware-description/</guid><description>Описание железа, виртуальных машин, топология сети:
Сервер: HP Proliant Microserver 16GB Ram 160GB SSD 1GB NIC Операционная система VmWare ESXi 5.5 Виртуальные машины Router Dnsmasq Developer Hub a.coreos b.coreos c.coreos d.coreos e.coreos Docker Containers a.httpd b.httpd c.httpd a.haproxy a.curl b.curl c.curl Сетевые настройки Network - 192.168.254.0/24 Router - 192.168.254.254 ESXi - 192.168.254.253 Dnsmasq - 192.168.254.252 Developer - 192.</description></item><item><title>CoreOS: Работа с контейнерами, создание базового образа</title><link>https://www.hdfilm.kz/coreos-docker-base-tools/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.hdfilm.kz/coreos-docker-base-tools/</guid><description>Кратко опишем, что нужно сделать, чтобы создать новый образ, как загрузить образ в репозиторий.
Создание нового образа
Мы не будем использовать публичные репозитории. все образы будут собраны нами. что позволит нам лучше контролировать образы, улучшить безопасность.
Для генерации нового образа воспользуемся скриптом mkimage-yum.sh. Данный скрипт создает CentOS из под CentOS.
Скачаем скрипт с github
cd /usr/local/bin wget https://raw.githubusercontent.com/docker/docker/master/contrib/mkimage-yum.sh chmod +x mkimage-yum.sh Создадим первый образ
sudo /usr/local/bin/mkimage-yum.sh centos Проверим образ</description></item><item><title>CoreOS: Создание контейнеров для тестовой площадки</title><link>https://www.hdfilm.kz/coreos-create-docker-images-for-test/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.hdfilm.kz/coreos-create-docker-images-for-test/</guid><description>Введение
Создать контейнеры для docker можно двумя способами:
ручное через dockerfile В данное время будем рассматривать только ручное создание. Для создания контейнеров используем Developers.
Контейнеры
curl
Запустить контейнер centos-base-with-localrepo - базовый контейнер, использующий локальные репозитории
docker run -i -t hub.nurm.local:5000/centos-base-with-localrepo /bin/bash Создать скрипт - бесконечный цикл, запрашивающий страницу
cat &amp;lt;&amp;lt;EOF &amp;gt; /root/curl_loop.sh #!/bin/bash CURL=/usr/bin/curl #echo $CURL while true do $CURL -silent http://a.haproxy.nurm.local/counter.php &amp;gt; /dev/null sleep 300 done EOF chmod + x /root/curl_loop.</description></item><item><title>CoreOS: Список использованной литературы</title><link>https://www.hdfilm.kz/coreos-list-of-used-links/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.hdfilm.kz/coreos-list-of-used-links/</guid><description/></item><item><title>CoreOS: Установка Private Repository</title><link>https://www.hdfilm.kz/coreos-setup-private-repository/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.hdfilm.kz/coreos-setup-private-repository/</guid><description>Установка Private Repository
Для чего нужен частный репозиторий:
Для локального хранения образов Docker. Для хранения образов, которые по требованиям безопасности нельзя выкладывать в общий доступ. Для ускорения создания новых образов, тестирования. Еще следует отметить, что большинство образов в публичных репозиториях никак не контролируется.
Шаги:
Установить минимальный образ CentOS Отключить selinux Настроить сеть, имя хоста Подключить yum репозиторий epel Провести обновление пакетов Создать папку /docker-registry yum install docker-io, docker-repository mkdir -p /usr/lib/python2.</description></item><item><title>CoreOS: Установка виртуальной машины Delevopers</title><link>https://www.hdfilm.kz/coreos-setup-developers-vm/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.hdfilm.kz/coreos-setup-developers-vm/</guid><description>Установка виртуальной машины Delevopers
Для чего нужна виртуальная машина Developers:
Для создания, тестирования новых образов Docker. Для push/pull образов Docker в частный репозитарий. Данная виртуальная машина будет полигоном для нашего кластера. Кузница новых образов, модернизации старых образов Docker. Вся грязная работа будет проводиться здесь. Кратко опишем, что нужно сделать, чтобы установить ОС.
Шаги:
Установить минимальный образ CentOS Отключить selinux Настроить сеть, имя хоста Подключить yum репозиторий epel Провести обновление пакетов Установка Docker</description></item><item><title>CoreOS: Установка кластера CoreOS ETCD2</title><link>https://www.hdfilm.kz/coreos-setup-coreos-cluster-etcd2/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.hdfilm.kz/coreos-setup-coreos-cluster-etcd2/</guid><description>Установка кластера CoreOS
Update: С февраля 2015 года coreos успел сменить etcd на etcd2. В связи с этим изменилась настройка серверов coreos. Здесь я изменил настройки для работы с более современными версиями coreos.
Рекомендую ознакомится со следующей статьей, здесь достаточно подробно описана технология coreos.
Для меня самой большой проблемой было понять, для чего нужен https://discovery.etcd.io/ и как быть, если в корпоративной сети нет доступа к этому ресурсу. Пока не прочел данную статью, где описан вариант Easy Development/Testing Cluster.</description></item><item><title>Кластер CoreOS для освоения Docker</title><link>https://www.hdfilm.kz/coreos-intro/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://www.hdfilm.kz/coreos-intro/</guid><description>Вводная часть
Предполагается, что все работы проводятся внутри предприятия с ограниченным доступом к ресурсам Internet. CentOS выбрана основой для виртуальных машин и контейнеров. На предприятие есть зеркала популярных репозиториев, нет необходимости в доступе к интернет для установки пакетов.
Данная статья - это конспектирование опыта изучения как работает кластер CoreOS, как работает Docker, развертывания кластера.
Данный кластер был развернут на работе, затем был развернут дома на домашнем сервере, для написания данной статьи.</description></item></channel></rss>